{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.transforms import spline_autoregressive, conditional_spline_autoregressive\n",
    "\n",
    "data_location = r'/home/taymaz/Documents/Project_VAE/material_vae/data/MP_v2.mat'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prediction model\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A general-purpose residual block for 1-dim inputs.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, dropout=0.65, zero_initialization=True, batch_norm=True):\n",
    "        super().__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(dim, dim) for _ in range(2)])\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.relu =  nn.ReLU()\n",
    "        if zero_initialization:\n",
    "            torch.nn.init.uniform_(self.linear_layers[-1].weight, -1e-3, 1e-3)\n",
    "            torch.nn.init.uniform_(self.linear_layers[-1].bias, -1e-3, 1e-3)\n",
    "        if batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList([nn.BatchNorm1d(dim, eps=1e-3) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        temps = inputs\n",
    "        if self.batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.relu(temps)\n",
    "        temps = self.linear_layers[0](temps)\n",
    "        if self.batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.relu(temps)\n",
    "        temps = self.dropout(temps)\n",
    "        temps = self.linear_layers[1](temps)\n",
    "        return inputs + temps\n",
    "\n",
    "    \n",
    "class ResidualNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A general-purpose residual network for 1-dim inputs. \n",
    "    Option to be used as a Gaussian encoder network (or mixture of Gaussian encoder network)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, num_blocks=2, dropout=0.65, batch_norm=True, gauss_encoder=False, gauss_mix=False, num_gauss = 14):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.initial_layer = nn.Linear(in_dim, hidden_dim)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(dim=hidden_dim, dropout=dropout, batch_norm=batch_norm) for _ in range(num_blocks)])\n",
    "        self.final_layer = nn.Linear(hidden_dim, out_dim)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.encode = gauss_encoder       \n",
    "        self.gaussian_mix = gauss_mix\n",
    "        self.num_gauss = num_gauss\n",
    "        # if using ResNet as a VAE encoder\n",
    "        if self.encode and not self.gaussian_mix:\n",
    "            self.final_layer_loc = nn.Linear(hidden_dim, out_dim)\n",
    "            self.final_layer_scale = nn.Linear(hidden_dim, out_dim)\n",
    "        if self.encode and self.gaussian_mix:\n",
    "            self.final_layers_loc = nn.ModuleList([nn.Linear(hidden_dim, out_dim) for _ in range(self.num_gauss)])\n",
    "            self.final_layers_scale = nn.ModuleList([nn.Linear(hidden_dim, out_dim) for _ in range(self.num_gauss)])\n",
    "            self.final_layers_weight = nn.ModuleList([nn.Linear(hidden_dim, 1) for _ in range(self.num_gauss)])\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        temps = self.initial_layer(inputs)\n",
    "        for block in self.blocks:\n",
    "            temps = block(temps)\n",
    "        if self.encode and not self.gaussian_mix:\n",
    "            mu = self.final_layer_loc(temps)\n",
    "            logvar = self.final_layer_scale(temps)\n",
    "            return mu, logvar\n",
    "        elif self.encode and self.gaussian_mix:\n",
    "            mus = torch.stack([self.final_layers_loc[n](temps) for n in range(self.num_gauss)])\n",
    "            logvars = torch.stack([self.final_layers_scale[n](temps) for n in range(self.num_gauss)])\n",
    "            weights = torch.stack([self.final_layers_weight[n](temps) for n in range(self.num_gauss)]).squeeze()\n",
    "            return mus, logvars, self.softmax(weights)\n",
    "        else:\n",
    "            outputs = self.final_layer(temps)\n",
    "            return outputs\n",
    "\n",
    "    \n",
    "class FlowVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional (Autoregressive) Spline Flow based VAE with ResNet encoder/decoder.\n",
    "    Two hierachies: structural and energetic.\n",
    "    Option to use a mixture of Gaussians as prior.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, num_flows, gauss_mix=False, num_gauss=14):\n",
    "        super(FlowVAE, self).__init__()\n",
    "        \n",
    "        self.input = input_dim\n",
    "        self.hidden = hidden_dim\n",
    "        self.latent = latent_dim\n",
    "        self.gaussian_mixture_prior = gauss_mix\n",
    "        self.resnet_encoder = ResidualNet(input_dim, latent_dim, hidden_dim, gauss_encoder=True, gauss_mix=gauss_mix, num_gauss=num_gauss)\n",
    "        self.resnet_decoder = ResidualNet(latent_dim, input_dim, hidden_dim)\n",
    "        self.numflow = num_flows\n",
    "        self.flow_structural = [conditional_spline_autoregressive(self.latent, context_dim=1) for _ in range(self.numflow)]\n",
    "        self.flow_energetic = [conditional_spline_autoregressive(self.latent, context_dim=1) for _ in range(self.numflow)]\n",
    "        self.flow_modules = nn.ModuleList(self.flow_structural + self.flow_energetic)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        if self.gaussian_mixture_prior:\n",
    "            mus, logvars, weights = self.resnet_encoder(x)\n",
    "            return mus, logvars, weights\n",
    "        else:\n",
    "            mu, logvar = self.resnet_encoder(x)\n",
    "            return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        out = self.resnet_decoder(z)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x, context_structure, context_energy):\n",
    "        if self.gaussian_mixture_prior:\n",
    "            mu, logvar, weights = self.encode(x)\n",
    "            mixture = dist.Categorical(weights.permute(1,0))\n",
    "            component = dist.Independent(dist.Normal(mu.permute(1,0,2), logvar.permute(1,0,2)), 1)\n",
    "            prior = dist.MixtureSameFamily(mixture, component) \n",
    "        else: \n",
    "            mu, logvar = self.encode(x)\n",
    "            prior = dist.Normal(mu, logvar)\n",
    "        \n",
    "        structural_embed = dist.ConditionalTransformedDistribution(prior, self.flow_structural)\n",
    "        energetic_embed = dist.ConditionalTransformedDistribution(structural_embed, self.flow_energetic)\n",
    "        with pyro.plate(\"xrd\", x.shape[0]):\n",
    "            z_structural = structural_embed.condition(context_structure).sample()\n",
    "            z_energetic = energetic_embed.condition(context_energy).sample()\n",
    "            \n",
    "        return self.decode(z_energetic), mu, logvar, z_energetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function here, the MAPE are set as criterion for cohesive energy prediction\n",
    "def simplevae_elbo_loss_function_with_energy(recon_x, x, mu, logvar):\n",
    "    MSE = nn.MSELoss(reduction='mean')(recon_x, x)\n",
    "    #MAPE_eng = torch.sum(torch.abs((pred_e-e)/e))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return 0.1 * MSE + 0.01 * KLD, MSE, KLD\n",
    "\n",
    "def pred_loss_CE(tar, tar_pred):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    CE_tar = loss(tar_pred,tar.squeeze())\n",
    "    return CE_tar\n",
    "\n",
    "def pred_loss_MSE(tar, tar_pred):\n",
    "    MSE = nn.MSELoss(reduction='mean')(tar_pred, tar) \n",
    "    return MSE\n",
    "\n",
    "def accuracy(tar, tar_pred):\n",
    "    acc = torch.sum(torch.argmax(tar_pred, dim=1).view(-1,1)==tar)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define auxiliary dataset class\n",
    "class ndarrayDataset(Dataset):\n",
    "    \"\"\"simple dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y_structure, y_energy):\n",
    "        super(ndarrayDataset, self).__init__()\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y_structure = torch.from_numpy(y_structure).float()\n",
    "        self.y_energy = torch.from_numpy(y_energy).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_structure[idx], self.y_energy[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (version 2)\n",
    "data = sio.loadmat(data_location)\n",
    "\n",
    "input_mat = data['MP']\n",
    "id = input_mat[:,0]\n",
    "atom_type = input_mat[:,1]\n",
    "X = input_mat[:,2:3602] # training data\n",
    "space_group = (input_mat[:,3602]-1).astype(int) # target value\n",
    "band_gap = input_mat[:,3603] # target value\n",
    "energy = input_mat[:,3604] # target value\n",
    "mag_moment = input_mat[:,3605] # target value\n",
    "energy_above_hull = input_mat[:,3606] # target value\n",
    "targets = input_mat[:,3602:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bravais = np.copy(space_group)\n",
    "for i, sg in enumerate(space_group):\n",
    "    if sg == 0 or sg == 1:\n",
    "        bravais[i] = 0\n",
    "    if sg == 2 or sg == 3 or sg == 5 or sg == 6 or sg == 9 or sg == 10 or sg == 12 or sg == 13:\n",
    "        bravais[i] = 1\n",
    "    if sg == 4 or sg == 7 or sg == 8 or sg == 11 or sg == 14:\n",
    "        bravais[i] = 2\n",
    "    if 15 <= sg <= 18 or 24 <= sg <= 33 or 46 <= sg <= 61:\n",
    "        bravais[i] = 3\n",
    "    if sg == 19 or sg == 20 or 34 <= sg <= 40 or 62 <= sg <= 67:\n",
    "        bravais[i] = 4\n",
    "    if sg == 21 or sg == 68 or sg == 69 or 41 <= sg <= 42:\n",
    "        bravais[i] = 5\n",
    "    if sg == 22 or sg == 23 or 43 <= sg <= 45 or 70 <= sg <= 73:\n",
    "        bravais[i] = 6\n",
    "    if 74 <= sg <= 77 or sg == 80 or 82 <= sg <= 85 or 88 <= sg <= 95 or 98 <= sg <= 105 or 110 <= sg <= 117 or 122 <= sg <= 137:\n",
    "        bravais[i] = 7\n",
    "    if 78 <= sg <= 79 or sg == 81 or 86 <= sg <= 87 or 96 <= sg <= 97 or 106 <= sg <= 109 or 118 <= sg <= 121 or 138 <= sg <= 141:\n",
    "        bravais[i] = 8\n",
    "    if 142 <= sg <= 166:\n",
    "        bravais[i] = 9\n",
    "    if 167 <= sg <= 193:\n",
    "        bravais[i] = 10\n",
    "    if sg == 194 or sg == 197 or 199 <= sg <= 200 or sg == 204 or 206 <= sg <= 207 or 211 <= sg <= 212 or sg == 214 or sg == 217 or 220 <= sg <= 223:\n",
    "        bravais[i] = 11\n",
    "    if sg == 195 or 201 <= sg <= 202 or 208 <= sg <= 209 or sg == 215 or sg == 218 or 224 <= sg <= 227:\n",
    "        bravais[i] = 12\n",
    "    if sg == 196 or sg == 198 or sg == 203 or sg == 205 or sg == 210 or sg == 213 or sg == 216 or sg == 219 or 228 <= sg <= 229:\n",
    "        bravais[i] = 13     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, energy_train, energy_test, bravais_train, bravais_test = train_test_split(X, energy, bravais, test_size=0.40, shuffle=True, random_state=9)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, tar_train, tar_test = train_test_split(X, bravais, test_size=0.40, shuffle=True, random_state=9)\n",
    "X_val1, X_val2, tar_val1, tar_val2 = train_test_split(X_test, tar_test, test_size=0.50, shuffle=True, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'y_energy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0e4c5a2cfe36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarrayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mv1_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarrayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_val1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'y_energy'"
     ]
    }
   ],
   "source": [
    "# add some parameters\n",
    "class Args:\n",
    "    batch_size = 256 \n",
    "    epochs_pre = 20     # pretraining epochs\n",
    "    epochs_vae = 1000   # VAE epochs\n",
    "    epochs_pred = 500   # prediction epochs\n",
    "    seed = 9            # random seed (default: 9)\n",
    "    log_interval = 10   # how many batches to wait before logging training status (default 10)\n",
    "    latent_dim = 15     # VAE latent space dimension\n",
    "    \n",
    "args=Args()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "train_dataset = ndarrayDataset(X_train, tar_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = args.batch_size)\n",
    "v1_dataset = ndarrayDataset(X_val1, tar_val1)\n",
    "v1_loader = DataLoader(v1_dataset, batch_size=1000)\n",
    "v1_loader2 = DataLoader(v1_dataset, batch_size=args.batch_size)\n",
    "v2_dataset = ndarrayDataset(X_val2, tar_val2)\n",
    "v2_loader = DataLoader(v2_dataset, batch_size=1000)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Body part of pretraining\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "structural_estimator_model = ResidualNet(3600, 14, int((3600+14)/2))\n",
    "structural_estimator_optimizer = optim.Adam(structural_estimator_model.parameters(), lr=1e-5)\n",
    "\n",
    "energetic_estimator_model = ResidualNet(3600, 1, int(3600/2))\n",
    "energetic_estimator_optimizer = optim.Adam(energetic_estimator_model.parameters(), lr=1e-5)\n",
    "\n",
    "def structural_estimator_train(epoch):\n",
    "    structural_estimator_model.train()\n",
    "    matches = 0\n",
    "    for batch_idx, (data, tar) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        tar = tar.view(-1,1).to(torch.long).to(device)\n",
    "        structural_estimator_optimizer.zero_grad()\n",
    "        tar_pred = structural_estimator_model(data)\n",
    "        loss = pred_loss_CE(tar, tar_pred)\n",
    "        loss.backward()\n",
    "        structural_estimator_optimizer.step()\n",
    "        matches += accuracy(tar, tar_pred).item()\n",
    "    accuracy = matches/len(X_val1)\n",
    "    return loss, accuracy\n",
    "\n",
    "def structural_estimator_test(epoch):\n",
    "    structural_estimator_model.eval()\n",
    "    matches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, tar) in enumerate(v1_loader):\n",
    "            data = data.to(device)\n",
    "            tar = tar.view(-1,1).to(torch.long).to(device)\n",
    "            structural_estimator_optimizer.zero_grad()\n",
    "            tar_pred = structural_estimator_model(data)\n",
    "            loss = pred_loss_CE(tar, tar_pred)\n",
    "            matches += accuracy(tar, tar_pred).item()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print(f'Epoch:{epoch}, pre-train val prediction loss: {loss.item()}')\n",
    "    accuracy = matches/len(X_val2)\n",
    "    return loss, accuracy\n",
    "\n",
    "def energetic_estimator_train(epoch):\n",
    "    energetic_estimator_model.train()\n",
    "    matches = 0\n",
    "    for batch_idx, (data, tar) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        tar = tar.view(-1,1).to(torch.long).to(device)\n",
    "        energetic_estimator_optimizer.zero_grad()\n",
    "        tar_pred = energetic_estimator_model(data)\n",
    "        loss = pred_loss_MSE(tar, tar_pred)\n",
    "        loss.backward()\n",
    "        energetic_estimator_optimizer.step()\n",
    "        matches += accuracy(tar, tar_pred).item()\n",
    "    accuracy = matches/len(X_val1)\n",
    "    return loss, accuracy\n",
    "\n",
    "def energetic_estimator_test(epoch):\n",
    "    energetic_estimator_model.eval()\n",
    "    matches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, tar) in enumerate(v1_loader):\n",
    "            data = data.to(device)\n",
    "            tar = tar.view(-1,1).to(torch.long).to(device)\n",
    "            energetic_estimator_optimizer.zero_grad()\n",
    "            tar_pred = energetic_estimator_model(data)\n",
    "            loss = pred_loss_MSE(tar, tar_pred)\n",
    "            matches += accuracy(tar, tar_pred).item()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print(f'Epoch:{epoch}, pre-train val prediction loss: {loss.item()}')\n",
    "    accuracy = matches/len(X_val2)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Body part of VAE training\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "vae_model = FlowVAE(input_dim=3600,hidden_dim=200,latent_dim=args.latent_dim,num_flows=3,gauss_mix=True,num_gauss=14).to(device)\n",
    "vae_optimizer = optim.Adam(vae_model.parameters(), lr=1e-5)\n",
    "\n",
    "def vae_train(epoch):\n",
    "    vae_model.train()\n",
    "    latent = []\n",
    "    for batch_idx, (data, tar_structure, tar_energy) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        tar_structure = tar.view(-1,1).to(device)\n",
    "        tar_energy = tar.view(-1,1).to(device)\n",
    "        vae_optimizer.zero_grad()\n",
    "        x_pred, mu, logvar, energetic_embed = vae_model(data, tar_structure, tar_energy)\n",
    "        latent.append(energetic_embed.detach().cpu().numpy())\n",
    "        loss, _, _ = simplevae_elbo_loss_function_with_energy(x_pred, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        vae_optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Total Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    return loss, latent\n",
    "\n",
    "\n",
    "def vae_test(epoch):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data, tar_structure, tar_energy) in enumerate(v1_loader):\n",
    "            data = data.to(device)\n",
    "            tar_structure = tar.view(-1,1).to(device)\n",
    "            tar_energy = tar.view(-1,1).to(device)\n",
    "            vae_optimizer.zero_grad()\n",
    "            x_pred, mu, logvar, _ = vae_model(data, tar_structure, tar_energy)\n",
    "            loss, _, _  = simplevae_elbo_loss_function_with_energy(x_pred, data, mu, logvar)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Body part of prediction model training\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "predictor_model = ResidualNet(args.latent_dim, 14, int((args.latent_dim+14)/2))\n",
    "predictor_optimizer = optim.Adam(model2.parameters(), lr=1e-5)\n",
    "\n",
    "def pred_train(epoch):\n",
    "    structural_estimator_model.eval()\n",
    "    energetic_estimator_model.eval()\n",
    "    vae_model.eval()\n",
    "    predictor_model.train()\n",
    "    latent = []\n",
    "    matches = 0\n",
    "    for batch_idx, (data, tar_structure, tar_energy) in enumerate(v1_loader2):\n",
    "        data = data.to(device)\n",
    "        context_structure = structural_estimator_model(data).argmax(dim = 1).view(-1,1)\n",
    "        context_energy = energetic_estimator_model(data).argmax(dim = 1).view(-1,1)\n",
    "        _,_,_, energetic_embedding = vae_model(data, context_structure, context_energy)\n",
    "        tar_structure = tar_structure.view(-1,1).to(torch.long).to(device)\n",
    "        tar_energy = tar_energy.view(-1,1).to(device)\n",
    "        predictor_optimizer.zero_grad()\n",
    "        pred_energy = predictor_model(energetic_embedding)\n",
    "        latent.append(energetic_embedding.detach().cpu().numpy())\n",
    "        loss = pred_loss(tar_energy, pred_energy)\n",
    "        loss.backward()\n",
    "        predictor_optimizer.step()\n",
    "        matches += accuracy(tar_energy, pred_energy).item()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Total Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    accuracy = matches/len(X_val1)\n",
    "    return loss, latent, accuracy\n",
    "    \n",
    "def pred_test(epoch):\n",
    "    structural_estimator_model.eval()\n",
    "    energetic_estimator_model.eval()\n",
    "    vae_model.eval()\n",
    "    predictor_model.eval()\n",
    "    latent = []\n",
    "    matches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, tar_structure, tar_energy) in enumerate(v2_loader):\n",
    "            data = data.to(device)\n",
    "            context_structure = structural_estimator_model(data).argmax(dim = 1).view(-1,1)\n",
    "            context_energy = energetic_estimator_model(data).argmax(dim = 1).view(-1,1)\n",
    "            _,_,_, energetic_embedding = vae_model(data, context_structure, context_energy)\n",
    "            tar_structure = tar_structure.view(-1,1).to(torch.long).to(device)\n",
    "            tar_energy = tar_energy.view(-1,1).to(device)\n",
    "            predictor_optimizer.zero_grad()\n",
    "            pred_energy = predictor_model(energetic_embedding)\n",
    "            latent.append(energetic_embedding.detach().cpu().numpy())\n",
    "            loss = pred_loss(tar_energy, pred_energy)\n",
    "            matches += accuracy(tar, tar_pred).item()\n",
    "    accuracy = matches/len(X_val2)\n",
    "    return loss, accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "pre_train_loss_list = []\n",
    "pre_test_loss_list = []\n",
    "pretrain_accuracy =[]\n",
    "pretest_accuracy = []\n",
    "for epoch in range(1, args.epochs_pre + 1):\n",
    "    pre_train_loss, acc_train = pre_pred_train(epoch)\n",
    "    pre_test_loss, acc_val = pre_pred_test(epoch)\n",
    "    pre_train_loss_list.append(pre_train_loss)\n",
    "    pre_test_loss_list.append(pre_test_loss)\n",
    "    pretrain_accuracy.append(acc_train)\n",
    "    pretest_accuracy.append(acc_val)\n",
    "print('pretraining done')\n",
    "\n",
    "train_err_list = []\n",
    "test_err_list = []\n",
    "latent_list = []\n",
    "for epoch in range(1, args.epochs_vae + 1):\n",
    "    train_err, latent = train(epoch)\n",
    "    test_err = test(epoch)\n",
    "    train_err_list.append(train_err)\n",
    "    test_err_list.append(test_err)\n",
    "    latent_list.append(latent)\n",
    "print('latent space training done')\n",
    "\n",
    "train_pred_loss_list = []\n",
    "test_pred_loss_list = []\n",
    "latent_list_pred = []\n",
    "train_accuracy =[]\n",
    "test_accuracy = []\n",
    "for epoch in range(1, args.epochs_pred + 1):\n",
    "    train_pred_loss, latent2, acc_train = train_pred(epoch)\n",
    "    test_pred_loss, acc_val = test_pred(epoch)\n",
    "    train_pred_loss_list.append(train_pred_loss)\n",
    "    test_pred_loss_list.append(test_pred_loss)\n",
    "    latent_list_pred.append(latent2)\n",
    "    train_accuracy.append(acc_train)\n",
    "    test_accuracy.append(acc_val)\n",
    "\n",
    "\n",
    "# The program will save the data for plotting and recovery of modeling\n",
    "# This part saves the MAPE loss in each epoch\n",
    "with open('MAPE_simpleVAE_%d.npz' % args.epochs_pred,'wb') as f:\n",
    "    np.savez(f, train_err = train_err_list, test_err = test_err_list)\n",
    "torch.save(model.state_dict(),'model_simpleVAE_%d.pth' % args.epochs_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average MAPE over all iterations\n",
    "plt.title(\"Error For Cohesive Energy Prediction\")\n",
    "plt.plot(train_err_list, label='train')\n",
    "plt.plot(test_err_list, label='test')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"KLD + MSE\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('simpleVAE_mape.png') # can be saved as .svg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, err in enumerate(train_err_list):\n",
    "    train_err_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_train_loss', train_err_list)\n",
    "\n",
    "for i, err in enumerate(test_err_list):\n",
    "    test_err_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_test_loss', test_err_list)\n",
    "\n",
    "for i, err in enumerate(pre_train_loss_list):\n",
    "    pre_train_loss_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_pre_train_loss', pre_train_loss_list)\n",
    "\n",
    "for i, err in enumerate(pre_test_loss_list):\n",
    "    pre_test_loss_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_pre_test_loss', pre_test_loss_list)\n",
    "\n",
    "for i, err in enumerate(train_pred_loss_list):\n",
    "    train_pred_loss_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_train_pred_loss', train_pred_loss_list)\n",
    "\n",
    "for i, err in enumerate(test_pred_loss_list):\n",
    "    test_pred_loss_list[i] = err.cpu().detach().numpy()\n",
    "np.save('vae_cond_mm_test_pred_loss', test_pred_loss_list)\n",
    "\n",
    "np.save('vae_cond_mm_label', latent_list)\n",
    "\n",
    "np.save('vae_cond_mm_label_pred', latent_list_pred)\n",
    "\n",
    "np.save('vae_cond_mm_train_acc', train_accuracy)\n",
    "\n",
    "np.save('vae_cond_mm_test_acc', test_accuracy)\n",
    "\n",
    "np.save('vae_cond_mm_pretrain_acc', pretrain_accuracy)\n",
    "\n",
    "np.save('vae_cond_mm_pretest_acc', pretest_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
