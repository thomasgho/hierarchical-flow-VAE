{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nsqs50ElShq9"
   },
   "source": [
    "##To do:\n",
    "\n",
    "- enforce SO(3) symmetry in coordinate space of crystals. Augment coordinate space data with SO(3) transformations, then enforce transformation equivariance in the loss function.\n",
    "- implement equivariant flows - these are just a variarion of continous normalizing flows (cnfs) (see eqn 8 https://papers.nips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf) where the 'vector field' of the flow is invariant (i.e. in simple terms this is our nn.Sequential() inside the self.flow() module of the vae). Explained in section 4/5 of https://arxiv.org/pdf/2006.02425.pdf. We want a network which respects the SO(3) symmetry of the materials. They refer to 'schnet' https://github.com/atomistic-machine-learning/schnetpack as an example network.\n",
    "- prepare data and shift augmented data. It might also be useful to augment broadened/noised/splitted/backgrounded data and combine all of these to feed into the vae. \n",
    "- look at the sampling scheme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "nn3DVaHl7nio",
    "outputId": "337e1116-86b8-46c8-8eb9-e17442accb6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdyn in /usr/local/lib/python3.7/dist-packages (0.2.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchdyn) (1.8.0+cu111)\n",
      "Requirement already satisfied: torchdiffeq>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from torchdyn) (0.2.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torchdyn) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torchdyn) (0.22.2.post1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from torchdyn) (0.9.0+cu111)\n",
      "Requirement already satisfied: pytorch-lightning>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from torchdyn) (1.2.5)\n",
      "Requirement already satisfied: dgl>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torchdyn) (0.6.0.post1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->torchdyn) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->torchdyn) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdyn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdyn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdyn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdyn) (2.8.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torchdyn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torchdyn) (1.0.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->torchdyn) (7.0.0)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (5.3.1)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (0.2.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (4.41.1)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (0.8.7)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (2.4.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=0.8.4->torchdyn) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.4.1->torchdyn) (2.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.4.1->torchdyn) (2.23.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torchdyn) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (3.7.2)\n",
      "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (3.7.4.post0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (3.12.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (0.4.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (1.27.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (1.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (3.3.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (0.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (54.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (1.8.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl>=0.4.1->torchdyn) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4.1->torchdyn) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4.1->torchdyn) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4.1->torchdyn) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4.1->torchdyn) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (3.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning>=0.8.4->torchdyn) (3.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=0.8.4->torchdyn) (0.4.8)\n",
      "Collecting git+https://github.com/google-research/torchsde.git\n",
      "  Cloning https://github.com/google-research/torchsde.git to /tmp/pip-req-build-q6v8a3_s\n",
      "  Running command git clone -q https://github.com/google-research/torchsde.git /tmp/pip-req-build-q6v8a3_s\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied (use --upgrade to upgrade): torchsde==0.2.5 from git+https://github.com/google-research/torchsde.git in /usr/local/lib/python3.7/dist-packages\n",
      "Collecting torch<1.8.0,>=1.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: boltons>=20.2.1 in /usr/local/lib/python3.7/dist-packages (from torchsde==0.2.5) (20.2.1)\n",
      "Requirement already satisfied: numpy==1.19.* in /usr/local/lib/python3.7/dist-packages (from torchsde==0.2.5) (1.19.5)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from torchsde==0.2.5) (0.1.2)\n",
      "Requirement already satisfied: scipy==1.5.* in /usr/local/lib/python3.7/dist-packages (from torchsde==0.2.5) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8.0,>=1.6.0->torchsde==0.2.5) (3.7.4.3)\n",
      "Building wheels for collected packages: torchsde\n",
      "  Building wheel for torchsde (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchsde: filename=torchsde-0.2.5-cp37-none-any.whl size=55592 sha256=66bd4a8a255a67e2c21079a97b2310479b5cd31dbeaf6c4cb1b834c6a6e591f1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezvvm2u6/wheels/31/b5/4b/53c7d7c124c1bbfebd2c5f429ca86b5e59f6cd4718dc0f1229\n",
      "Successfully built torchsde\n",
      "\u001b[31mERROR: torchvision 0.9.0+cu111 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchaudio 0.8.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.8.0+cu111\n",
      "    Uninstalling torch-1.8.0+cu111:\n",
      "      Successfully uninstalled torch-1.8.0+cu111\n",
      "Successfully installed torch-1.7.1\n",
      "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (3.7.4.3)\n",
      "Requirement already satisfied: antialiased-cnns in /usr/local/lib/python3.7/dist-packages (0.3)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562c96502000 @  0x7f7214b251e7 0x562c93b66f48 0x562c93b319c7 0x562c93cb0655 0x562c93c4a828 0x562c93b35292 0x562c93c136ae 0x562c93b34ee9 0x562c93c2699d 0x562c93ba8fe9 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562d0c76e000 @  0x7f7214b251e7 0x562c93b66f48 0x562c93b319c7 0x562c93c481c7 0x562c93b3500c 0x562c93c2699d 0x562c93ba8fe9 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba586a 0x562c93b3669a\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562d829da000 @  0x7f7214b251e7 0x562c93b67fb8 0x562c93c223a6 0x562c93b34e8d 0x562c93c2699d 0x562c93ba8fe9 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba586a 0x562c93b3669a 0x562c93ba4a45 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3e0d 0x562c93b3702c\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562df8c46000 @  0x7f7214b251e7 0x562c93b66f48 0x562c93c22d9c 0x562c93c1ce59 0x562c93ba4fad 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba586a 0x562c93b3669a 0x562c93ba4a45 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562e6f6fc000 @  0x7f7214b251e7 0x562c93b66f48 0x562c93b319c7 0x562c93c47eca 0x562c93b3460f 0x562c93b74c25 0x562c93b357f2 0x562c93ba8d75 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba586a 0x562c93b3669a 0x562c93ba4a45 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e\n",
      "tcmalloc: large alloc 1982251008 bytes == 0x562e6f6fc000 @  0x7f7214b251e7 0x562c93b66f48 0x562c93b319c7 0x562c93cb0655 0x562c93c4a828 0x562c93b35292 0x562c93c136ae 0x562c93b34ee9 0x562c93c2699d 0x562c93ba8fe9 0x562c93b3669a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3e0d 0x562c93b3702c 0x562c93b37231 0x562c93ba61e6 0x562c93ba3b0e\n",
      "tcmalloc: large alloc 2477817856 bytes == 0x562c96502000 @  0x7f7214b26615 0x562c93b3206c 0x562c93c11eba 0x562c93b34e8d 0x562c93c2699d 0x562c93ba8fe9 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93b3669a 0x562c93ba4c9e 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba586a 0x562c93ba3b0e 0x562c93b3677a 0x562c93ba4c9e 0x562c93ba3e0d 0x562c93b3677a\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: torchvision==0.9.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.9.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.0.0)\n",
      "\u001b[31mERROR: torchsde 0.2.5 has requirement torch<1.8.0,>=1.6.0, but you'll have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "Successfully installed torch-1.8.0+cu111\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchdyn\n",
    "#!pip install git+https://github.com/google-research/torchsde.git\n",
    "#!pip install torchdiffeq\n",
    "#!pip install antialiased-cnns\n",
    "#!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "absolute-decade",
    "outputId": "5406b0fa-0cee-47fd-b05f-c3d7cc082ffe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45070c3b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "from torchdyn.models import *\n",
    "from torchdyn import *\n",
    "from torchdyn.datasets import *\n",
    "import antialiased_cnns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stock-driver"
   },
   "outputs": [],
   "source": [
    "# load\n",
    "data = pd.read_csv('/content/drive/MyDrive/material-VAE/new_vae/theor.csv', index_col=0)\n",
    "data = data.iloc[1:,]\n",
    "xrd = np.delete(data.values, list(range(0, data.shape[1], 2)), axis=1)\n",
    "angle = np.delete(data.values, list(range(1, data.shape[1], 2)), axis=1)\n",
    "xrd, angle = np.transpose(xrd), np.transpose(angle)\n",
    "# plt.plot(angle[0], xrd[0])\n",
    "\n",
    "# normalize\n",
    "xrd_scale = StandardScaler()\n",
    "xrd = xrd_scale.fit_transform(xrd)\n",
    "\n",
    "# prepare for convoultions [batch_size, channels, features] - channels=2 (one for xrd one for angle)\n",
    "# X = []\n",
    "# for i in range(xrd.shape[0]):\n",
    "#     X.append(np.vstack((xrd[i], angle[i])))\n",
    "# X = np.array(X)\n",
    "\n",
    "# prepare for convoultions [batch_size, channels, features] - channels=1\n",
    "X = np.expand_dims(xrd, axis=1)\n",
    "\n",
    "# label\n",
    "y = pd.read_csv('/content/drive/MyDrive/material-VAE/new_vae/label_theo.csv', header=None, index_col=0)\n",
    "y = np.delete(y.values, list(range(0, y.shape[0], 2)), axis=0)\n",
    "y = np.ravel(y).tolist()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crazy-manchester"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "trainset = Dataset(X, y)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "del xrd, angle, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agricultural-apartment"
   },
   "outputs": [],
   "source": [
    "# helper- put PrintSize() at any point in the nn.Sequential() and it will show the network dimension at that point\n",
    "# e.g. nn.Sequential(ConvODE,\n",
    "#                    PrintSize(),\n",
    "#                    nn.Linear(),\n",
    "#                    PrintSize())\n",
    "class PrintSize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintSize, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "# https://github.com/DiffEqML/torchdyn/blob/master/tutorials/08_hamiltonian_nets.ipynb\n",
    "# easy wrapper for any nn.Sequential() network\n",
    "class HNN(nn.Module):\n",
    "    def __init__(self, Hamiltonian:nn.Module, dim=1):\n",
    "        super().__init__()\n",
    "        self.H = Hamiltonian\n",
    "        self.n = dim\n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            x = x.requires_grad_(True)\n",
    "            gradH = torch.autograd.grad(self.H(x).sum(), x, allow_unused=False, create_graph=True)[0] \n",
    "        return torch.cat([gradH[:,self.n:], -gradH[:,:self.n]], 1).to(x)\n",
    "    \n",
    "# calculating the Jacobian trace for continous normalizing flows    \n",
    "def autograd_trace(x_out, x_in, **kwargs):\n",
    "    \"\"\"Standard brute-force means of obtaining trace of the Jacobian, O(d) calls to autograd\"\"\"\n",
    "    trJ = 0.\n",
    "    for i in range(x_in.shape[1]):\n",
    "        trJ += torch.autograd.grad(x_out[:, i].sum(), x_in, allow_unused=False, create_graph=True)[0][:, i]  \n",
    "    return trJ\n",
    "\n",
    "# https://github.com/DiffEqML/torchdyn/blob/master/tutorials/07a_continuous_normalizing_flows.ipynb\n",
    "# easy wrapper for any nn.Sequential() transformation\n",
    "class CNF(nn.Module):\n",
    "    def __init__(self, net, trace_estimator=None, noise_dist=None):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.trace_estimator = trace_estimator if trace_estimator is not None else autograd_trace;\n",
    "        self.noise_dist, self.noise = noise_dist, None\n",
    "        if self.trace_estimator in REQUIRES_NOISE:\n",
    "            assert self.noise_dist is not None, 'This type of trace estimator requires specification of a noise distribution'\n",
    "            \n",
    "    def forward(self, x):   \n",
    "        with torch.set_grad_enabled(True):\n",
    "            x_in = torch.autograd.Variable(x[:,1:], requires_grad=True).to(x) # first dimension reserved to divergence propagation          \n",
    "            # the neural network will handle the data-dynamics here\n",
    "            x_out = self.net(x_in)\n",
    "                \n",
    "            trJ = self.trace_estimator(x_out, x_in, noise=self.noise)\n",
    "        return torch.cat([-trJ[:, None], x_out], 1) + 0*x # `+ 0*x` has the only purpose of connecting x[:, 0] to autograd graph\n",
    "\n",
    "# helps reweight the convolutional channels at the end of a CNN\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        reduced_channels = max(channel // reduction, int(channel ** 0.5))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, reduced_channels, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduced_channels, channel, bias=False),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, = x.shape[:2]\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "# replace ReLU \n",
    "class SwishImplementation(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return SwishImplementation.apply(x)\n",
    "       \n",
    "# easy to use class version of this: https://github.com/DiffEqML/torchdyn/blob/master/tutorials/06_higher_order.ipynb\n",
    "# can be used as a simple network: NeuralODE(in, out, hidden)\n",
    "class NeuralODE(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A general-purpose high order ode network for 1-dim inputs.\n",
    "    Option to be used as a Gaussian encoder network (or mixture of Gaussian encoder network)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, order=4, batch_norm=True, gauss_encoder=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.initial_layer = nn.Linear(in_dim, hidden_dim)\n",
    "        self.nde = NeuralDE(\n",
    "            nn.Sequential(\n",
    "                nn.BatchNorm1d(hidden_dim*order),\n",
    "                Swish(),\n",
    "                nn.Linear(hidden_dim*order, hidden_dim*order),\n",
    "                nn.BatchNorm1d(hidden_dim*order),\n",
    "                Swish(),\n",
    "                nn.Linear(hidden_dim*order, hidden_dim)),\n",
    "            solver='euler', \n",
    "            order=order,\n",
    "            s_span=torch.linspace(0, 1, 5))\n",
    "        self.augment = Augmenter(augment_dims=hidden_dim*(order-1))\n",
    "        self.final_layer = nn.Linear(hidden_dim*order, out_dim)\n",
    "        \n",
    "        # if using as a VAE encoder:\n",
    "        self.encode = gauss_encoder\n",
    "        if self.encode:\n",
    "            self.final_layer_loc = nn.Linear(hidden_dim*order, out_dim)\n",
    "            self.final_layer_scale = nn.Linear(hidden_dim*order, out_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        temps = self.initial_layer(inputs)\n",
    "        temps = self.nde(self.augment(temps))\n",
    "        if self.encode:\n",
    "            loc = self.final_layer_loc(temps)\n",
    "            scale = torch.exp(self.final_layer_scale(temps))\n",
    "            return loc, scale\n",
    "        else:\n",
    "            outputs = self.final_layer(temps)\n",
    "            return outputs\n",
    "\n",
    "\n",
    "# just a convoultional nn wrapped in the Hamiltonian class above\n",
    "# experiment with max/avg pooling (see https://github.com/adobe/antialiased-cnns) ??\n",
    "# see https://github.com/DiffEqML/torchdyn/blob/master/tutorials/04_augmentation_strategies.ipynb for 'augmentation'\n",
    "class ConvODE(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A general-purpose augmented convolutional ode network for 1-dim inputs. \n",
    "    The network parametrised by Hamilton's canonical differential equations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, augment_dim, channel_length, transpose=False, canonical_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.augment = Augmenter(augment_func=nn.Linear(channel_length, channel_length)) # or initialize augmented dim to zero: Augmenter(augment_dims=augment_dim)\n",
    "        self.transpose = transpose\n",
    "        if transpose == False:\n",
    "            self.ham_func = HNN(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(augment_dim+in_channels, out_channels, kernel_size=8, stride=8),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    Swish(),\n",
    "                    nn.Conv1d(out_channels, out_channels, kernel_size=5, stride=5),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    Swish(),\n",
    "                    nn.Conv1d(out_channels, in_channels, kernel_size=3, stride=1),\n",
    "                    nn.BatchNorm1d(in_channels),\n",
    "                    Swish(),\n",
    "                    antialiased_cnns.BlurPool1D(in_channels, stride=3),\n",
    "                    SqueezeExcitation(in_channels, reduction=8)),\n",
    "                dim=canonical_dim)\n",
    "        else:\n",
    "            self.ham_func = HNN(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose1d(augment_dim+in_channels, out_channels, kernel_size=3, stride=1),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    Swish(),\n",
    "                    antialiased_cnns.BlurPool1D(out_channels, stride=3),\n",
    "                    nn.ConvTranspose1d(out_channels, out_channels, kernel_size=5, stride=5),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    Swish(),\n",
    "                    nn.ConvTranspose1d(out_channels, out_channels, kernel_size=8, stride=8),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    Swish(),\n",
    "                    SqueezeExcitation(out_channels, reduction=8)),\n",
    "                dim=canonical_dim)\n",
    "        self.nde = NeuralDE(\n",
    "            self.ham_func,\n",
    "            solver='euler',\n",
    "            s_span=torch.linspace(0, 1, 5))\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.swish = Swish()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        temps = self.swish(self.bn(inputs))\n",
    "        outputs = self.nde(self.augment(temps))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# encoder/decoder with continous normalizing flows in between\n",
    "# inside CNF() is what I presume they call the 'vector field' and what they want to make invariant\n",
    "# I save and return the Jacobian trace of the flow so I can add it to the loss function\n",
    "# copied how Yi did it under VAENF_loss(): https://github.com/CVC-Lab/Material_VAE/blob/master/loss_function.py  \n",
    "class FlowODEVAE(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    1D convolutional ODE-VAE with continuous normalizing flo Sampling of Coupled Particle Systemws.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim, in_channels, conv_channels, augment_dim, latent_dim, order=4, canonical_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten_dim = in_channels*in_dim\n",
    "        self.flatten_aug_dim = (in_channels+augment_dim)*in_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvODE(in_channels, conv_channels, augment_dim, in_dim, canonical_dim=canonical_dim),\n",
    "            nn.Flatten(),\n",
    "            NeuralODE(self.flatten_aug_dim, latent_dim, int(self.flatten_aug_dim/8), order=order, gauss_encoder=True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            NeuralODE(latent_dim, self.flatten_dim, int(self.flatten_dim/8), order=order),\n",
    "            nn.Unflatten(1, (in_channels, in_dim)),\n",
    "            ConvODE(in_channels, conv_channels, augment_dim, in_dim, transpose=True),\n",
    "            nn.Conv1d(in_channels+augment_dim, in_channels, kernel_size=1))\n",
    "        self.flow = NeuralDE(\n",
    "            CNF(nn.Sequential(\n",
    "                    nn.Linear(latent_dim, 64),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(64, latent_dim)),\n",
    "                    trace_estimator=autograd_trace), #hutch_trace\n",
    "            solver='dopri5',  \n",
    "            sensitivity='adjoint',\n",
    "            s_span=torch.linspace(0, 1, 2),\n",
    "            atol=1e-4,\n",
    "            rtol=1e-4)\n",
    "        self.augment = Augmenter(augment_idx=1, augment_dims=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        loc, scale = self.encoder(inputs)\n",
    "        z_prior = torch.distributions.Normal(loc, scale).sample()\n",
    "        transform = self.flow(self.augment(z_prior))\n",
    "        z_flow, trace_J = transform[:,1:], transform[:,0]\n",
    "        outputs = self.decoder(z_flow)\n",
    "        return outputs, loc, scale, z_flow, trace_J\n",
    "        \n",
    "        \n",
    "def Loss(X, X_hat, mu, var, trace_J):\n",
    "    KLD = -0.5 * torch.sum(1 + torch.log(var) - mu.pow(2) - var)\n",
    "    MSE = nn.MSELoss(reduction='mean')(X_hat, X) #(X-X_hat).pow(2).sum()/ X.numel()\n",
    "    return MSE + (KLD/y.numel()) - trace_J.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "subject-binding",
    "outputId": "f3696067-9331-4ecb-fe3b-806e98d0ac25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/164 (0%)]\t Loss: 38.306915\n",
      "Train Epoch: 0 [112/164 (64%)]\t Loss: 35.143210\n",
      "Train Epoch: 1 [0/164 (0%)]\t Loss: 33.439955\n",
      "Train Epoch: 1 [112/164 (64%)]\t Loss: 29.065310\n",
      "Train Epoch: 2 [0/164 (0%)]\t Loss: 27.254167\n",
      "Train Epoch: 2 [112/164 (64%)]\t Loss: 29.036781\n",
      "Train Epoch: 3 [0/164 (0%)]\t Loss: 27.894415\n",
      "Train Epoch: 3 [112/164 (64%)]\t Loss: 27.856854\n",
      "Train Epoch: 4 [0/164 (0%)]\t Loss: 24.113286\n",
      "Train Epoch: 4 [112/164 (64%)]\t Loss: 20.685412\n",
      "Train Epoch: 5 [0/164 (0%)]\t Loss: 19.069180\n",
      "Train Epoch: 5 [112/164 (64%)]\t Loss: 18.017270\n",
      "Train Epoch: 6 [0/164 (0%)]\t Loss: 16.606506\n",
      "Train Epoch: 6 [112/164 (64%)]\t Loss: 16.506581\n",
      "Train Epoch: 7 [0/164 (0%)]\t Loss: 14.800609\n",
      "Train Epoch: 7 [112/164 (64%)]\t Loss: 16.206588\n",
      "Train Epoch: 8 [0/164 (0%)]\t Loss: 13.824829\n",
      "Train Epoch: 8 [112/164 (64%)]\t Loss: 14.378947\n",
      "Train Epoch: 9 [0/164 (0%)]\t Loss: 13.380656\n",
      "Train Epoch: 9 [112/164 (64%)]\t Loss: 12.182421\n",
      "Train Epoch: 10 [0/164 (0%)]\t Loss: 11.856777\n",
      "Train Epoch: 10 [112/164 (64%)]\t Loss: 11.240393\n",
      "Train Epoch: 11 [0/164 (0%)]\t Loss: 12.628927\n",
      "Train Epoch: 11 [112/164 (64%)]\t Loss: 11.014990\n",
      "Train Epoch: 12 [0/164 (0%)]\t Loss: 10.708422\n",
      "Train Epoch: 12 [112/164 (64%)]\t Loss: 10.072421\n",
      "Train Epoch: 13 [0/164 (0%)]\t Loss: 10.076413\n",
      "Train Epoch: 13 [112/164 (64%)]\t Loss: 9.626956\n",
      "Train Epoch: 14 [0/164 (0%)]\t Loss: 9.572283\n",
      "Train Epoch: 14 [112/164 (64%)]\t Loss: 10.169580\n",
      "Train Epoch: 15 [0/164 (0%)]\t Loss: 8.787571\n",
      "Train Epoch: 15 [112/164 (64%)]\t Loss: 8.272070\n",
      "Train Epoch: 16 [0/164 (0%)]\t Loss: 10.091643\n",
      "Train Epoch: 16 [112/164 (64%)]\t Loss: 8.638953\n",
      "Train Epoch: 17 [0/164 (0%)]\t Loss: 9.780977\n",
      "Train Epoch: 17 [112/164 (64%)]\t Loss: 9.618117\n",
      "Train Epoch: 18 [0/164 (0%)]\t Loss: 7.778582\n",
      "Train Epoch: 18 [112/164 (64%)]\t Loss: 7.644001\n",
      "Train Epoch: 19 [0/164 (0%)]\t Loss: 7.017253\n",
      "Train Epoch: 19 [112/164 (64%)]\t Loss: 6.847732\n",
      "Train Epoch: 20 [0/164 (0%)]\t Loss: 6.630759\n",
      "Train Epoch: 20 [112/164 (64%)]\t Loss: 6.477787\n",
      "Train Epoch: 21 [0/164 (0%)]\t Loss: 8.130588\n",
      "Train Epoch: 21 [112/164 (64%)]\t Loss: 7.358023\n",
      "Train Epoch: 22 [0/164 (0%)]\t Loss: 6.137085\n",
      "Train Epoch: 22 [112/164 (64%)]\t Loss: 6.667186\n",
      "Train Epoch: 23 [0/164 (0%)]\t Loss: 6.408296\n",
      "Train Epoch: 23 [112/164 (64%)]\t Loss: 6.388025\n",
      "Train Epoch: 24 [0/164 (0%)]\t Loss: 5.947478\n",
      "Train Epoch: 24 [112/164 (64%)]\t Loss: 6.414959\n",
      "Train Epoch: 25 [0/164 (0%)]\t Loss: 5.726392\n",
      "Train Epoch: 25 [112/164 (64%)]\t Loss: 6.241640\n",
      "Train Epoch: 26 [0/164 (0%)]\t Loss: 5.798728\n",
      "Train Epoch: 26 [112/164 (64%)]\t Loss: 5.393455\n",
      "Train Epoch: 27 [0/164 (0%)]\t Loss: 5.192074\n",
      "Train Epoch: 27 [112/164 (64%)]\t Loss: 6.153951\n",
      "Train Epoch: 28 [0/164 (0%)]\t Loss: 6.110951\n",
      "Train Epoch: 28 [112/164 (64%)]\t Loss: 5.144538\n",
      "Train Epoch: 29 [0/164 (0%)]\t Loss: 5.280361\n",
      "Train Epoch: 29 [112/164 (64%)]\t Loss: 5.944909\n",
      "Train Epoch: 30 [0/164 (0%)]\t Loss: 5.239624\n",
      "Train Epoch: 30 [112/164 (64%)]\t Loss: 5.063286\n",
      "Train Epoch: 31 [0/164 (0%)]\t Loss: 4.550162\n",
      "Train Epoch: 31 [112/164 (64%)]\t Loss: 4.672022\n",
      "Train Epoch: 32 [0/164 (0%)]\t Loss: 4.356112\n",
      "Train Epoch: 32 [112/164 (64%)]\t Loss: 5.058248\n",
      "Train Epoch: 33 [0/164 (0%)]\t Loss: 4.960441\n",
      "Train Epoch: 33 [112/164 (64%)]\t Loss: 4.402640\n",
      "Train Epoch: 34 [0/164 (0%)]\t Loss: 4.825412\n",
      "Train Epoch: 34 [112/164 (64%)]\t Loss: 4.764577\n",
      "Train Epoch: 35 [0/164 (0%)]\t Loss: 4.205864\n",
      "Train Epoch: 35 [112/164 (64%)]\t Loss: 4.690156\n",
      "Train Epoch: 36 [0/164 (0%)]\t Loss: 4.495722\n",
      "Train Epoch: 36 [112/164 (64%)]\t Loss: 5.161815\n",
      "Train Epoch: 37 [0/164 (0%)]\t Loss: 4.198150\n",
      "Train Epoch: 37 [112/164 (64%)]\t Loss: 3.989383\n",
      "Train Epoch: 38 [0/164 (0%)]\t Loss: 4.307805\n",
      "Train Epoch: 38 [112/164 (64%)]\t Loss: 4.195781\n",
      "Train Epoch: 39 [0/164 (0%)]\t Loss: 3.950173\n",
      "Train Epoch: 39 [112/164 (64%)]\t Loss: 3.970970\n",
      "Train Epoch: 40 [0/164 (0%)]\t Loss: 3.827541\n",
      "Train Epoch: 40 [112/164 (64%)]\t Loss: 3.854051\n",
      "Train Epoch: 41 [0/164 (0%)]\t Loss: 3.556139\n",
      "Train Epoch: 41 [112/164 (64%)]\t Loss: 3.803628\n",
      "Train Epoch: 42 [0/164 (0%)]\t Loss: 3.698251\n",
      "Train Epoch: 42 [112/164 (64%)]\t Loss: 3.663542\n",
      "Train Epoch: 43 [0/164 (0%)]\t Loss: 3.786303\n",
      "Train Epoch: 43 [112/164 (64%)]\t Loss: 3.579587\n",
      "Train Epoch: 44 [0/164 (0%)]\t Loss: 3.564238\n",
      "Train Epoch: 44 [112/164 (64%)]\t Loss: 3.715150\n",
      "Train Epoch: 45 [0/164 (0%)]\t Loss: 3.972903\n",
      "Train Epoch: 45 [112/164 (64%)]\t Loss: 3.501516\n",
      "Train Epoch: 46 [0/164 (0%)]\t Loss: 3.525531\n",
      "Train Epoch: 46 [112/164 (64%)]\t Loss: 3.659528\n",
      "Train Epoch: 47 [0/164 (0%)]\t Loss: 3.151179\n",
      "Train Epoch: 47 [112/164 (64%)]\t Loss: 3.102163\n",
      "Train Epoch: 48 [0/164 (0%)]\t Loss: 2.936828\n",
      "Train Epoch: 48 [112/164 (64%)]\t Loss: 3.234287\n",
      "Train Epoch: 49 [0/164 (0%)]\t Loss: 2.973075\n",
      "Train Epoch: 49 [112/164 (64%)]\t Loss: 3.408878\n",
      "Train Epoch: 50 [0/164 (0%)]\t Loss: 3.011247\n",
      "Train Epoch: 50 [112/164 (64%)]\t Loss: 3.368456\n",
      "Train Epoch: 51 [0/164 (0%)]\t Loss: 3.278516\n",
      "Train Epoch: 51 [112/164 (64%)]\t Loss: 3.490939\n",
      "Train Epoch: 52 [0/164 (0%)]\t Loss: 3.461876\n",
      "Train Epoch: 52 [112/164 (64%)]\t Loss: 2.808636\n",
      "Train Epoch: 53 [0/164 (0%)]\t Loss: 3.317067\n",
      "Train Epoch: 53 [112/164 (64%)]\t Loss: 3.398269\n",
      "Train Epoch: 54 [0/164 (0%)]\t Loss: 2.936720\n",
      "Train Epoch: 54 [112/164 (64%)]\t Loss: 3.279958\n",
      "Train Epoch: 55 [0/164 (0%)]\t Loss: 3.136170\n",
      "Train Epoch: 55 [112/164 (64%)]\t Loss: 2.911535\n",
      "Train Epoch: 56 [0/164 (0%)]\t Loss: 2.646446\n",
      "Train Epoch: 56 [112/164 (64%)]\t Loss: 2.711265\n",
      "Train Epoch: 57 [0/164 (0%)]\t Loss: 3.111811\n",
      "Train Epoch: 57 [112/164 (64%)]\t Loss: 2.933985\n",
      "Train Epoch: 58 [0/164 (0%)]\t Loss: 2.723247\n",
      "Train Epoch: 58 [112/164 (64%)]\t Loss: 2.928837\n",
      "Train Epoch: 59 [0/164 (0%)]\t Loss: 2.679982\n",
      "Train Epoch: 59 [112/164 (64%)]\t Loss: 2.876177\n",
      "Train Epoch: 60 [0/164 (0%)]\t Loss: 2.764777\n",
      "Train Epoch: 60 [112/164 (64%)]\t Loss: 2.620132\n",
      "Train Epoch: 61 [0/164 (0%)]\t Loss: 2.957032\n",
      "Train Epoch: 61 [112/164 (64%)]\t Loss: 2.663414\n",
      "Train Epoch: 62 [0/164 (0%)]\t Loss: 2.821334\n",
      "Train Epoch: 62 [112/164 (64%)]\t Loss: 3.056250\n",
      "Train Epoch: 63 [0/164 (0%)]\t Loss: 2.608320\n",
      "Train Epoch: 63 [112/164 (64%)]\t Loss: 2.428508\n",
      "Train Epoch: 64 [0/164 (0%)]\t Loss: 2.904406\n",
      "Train Epoch: 64 [112/164 (64%)]\t Loss: 2.764203\n",
      "Train Epoch: 65 [0/164 (0%)]\t Loss: 2.529409\n",
      "Train Epoch: 65 [112/164 (64%)]\t Loss: 2.437217\n",
      "Train Epoch: 66 [0/164 (0%)]\t Loss: 2.388184\n",
      "Train Epoch: 66 [112/164 (64%)]\t Loss: 2.377623\n",
      "Train Epoch: 67 [0/164 (0%)]\t Loss: 2.456559\n",
      "Train Epoch: 67 [112/164 (64%)]\t Loss: 2.378273\n",
      "Train Epoch: 68 [0/164 (0%)]\t Loss: 2.576975\n",
      "Train Epoch: 68 [112/164 (64%)]\t Loss: 2.228318\n",
      "Train Epoch: 69 [0/164 (0%)]\t Loss: 2.035395\n",
      "Train Epoch: 69 [112/164 (64%)]\t Loss: 2.411793\n",
      "Train Epoch: 70 [0/164 (0%)]\t Loss: 2.631581\n",
      "Train Epoch: 70 [112/164 (64%)]\t Loss: 2.043471\n",
      "Train Epoch: 71 [0/164 (0%)]\t Loss: 2.538375\n",
      "Train Epoch: 71 [112/164 (64%)]\t Loss: 2.275605\n",
      "Train Epoch: 72 [0/164 (0%)]\t Loss: 2.569678\n",
      "Train Epoch: 72 [112/164 (64%)]\t Loss: 2.346077\n",
      "Train Epoch: 73 [0/164 (0%)]\t Loss: 2.625736\n",
      "Train Epoch: 73 [112/164 (64%)]\t Loss: 2.881237\n",
      "Train Epoch: 74 [0/164 (0%)]\t Loss: 2.416346\n",
      "Train Epoch: 74 [112/164 (64%)]\t Loss: 2.307515\n",
      "Train Epoch: 75 [0/164 (0%)]\t Loss: 2.144420\n",
      "Train Epoch: 75 [112/164 (64%)]\t Loss: 2.437570\n",
      "Train Epoch: 76 [0/164 (0%)]\t Loss: 2.534825\n",
      "Train Epoch: 76 [112/164 (64%)]\t Loss: 1.986143\n",
      "Train Epoch: 77 [0/164 (0%)]\t Loss: 2.192547\n",
      "Train Epoch: 77 [112/164 (64%)]\t Loss: 1.984498\n",
      "Train Epoch: 78 [0/164 (0%)]\t Loss: 2.395018\n",
      "Train Epoch: 78 [112/164 (64%)]\t Loss: 2.217455\n",
      "Train Epoch: 79 [0/164 (0%)]\t Loss: 2.396690\n",
      "Train Epoch: 79 [112/164 (64%)]\t Loss: 1.946948\n",
      "Train Epoch: 80 [0/164 (0%)]\t Loss: 2.495976\n",
      "Train Epoch: 80 [112/164 (64%)]\t Loss: 2.701897\n",
      "Train Epoch: 81 [0/164 (0%)]\t Loss: 2.074023\n",
      "Train Epoch: 81 [112/164 (64%)]\t Loss: 2.157793\n",
      "Train Epoch: 82 [0/164 (0%)]\t Loss: 2.065937\n",
      "Train Epoch: 82 [112/164 (64%)]\t Loss: 1.956213\n",
      "Train Epoch: 83 [0/164 (0%)]\t Loss: 1.998564\n",
      "Train Epoch: 83 [112/164 (64%)]\t Loss: 1.851299\n",
      "Train Epoch: 84 [0/164 (0%)]\t Loss: 2.123369\n",
      "Train Epoch: 84 [112/164 (64%)]\t Loss: 1.701229\n",
      "Train Epoch: 85 [0/164 (0%)]\t Loss: 2.472364\n",
      "Train Epoch: 85 [112/164 (64%)]\t Loss: 2.200842\n",
      "Train Epoch: 86 [0/164 (0%)]\t Loss: 1.857894\n",
      "Train Epoch: 86 [112/164 (64%)]\t Loss: 2.194832\n",
      "Train Epoch: 87 [0/164 (0%)]\t Loss: 1.973765\n",
      "Train Epoch: 87 [112/164 (64%)]\t Loss: 1.778548\n",
      "Train Epoch: 88 [0/164 (0%)]\t Loss: 2.167312\n",
      "Train Epoch: 88 [112/164 (64%)]\t Loss: 1.917479\n",
      "Train Epoch: 89 [0/164 (0%)]\t Loss: 1.707919\n",
      "Train Epoch: 89 [112/164 (64%)]\t Loss: 2.059320\n",
      "Train Epoch: 90 [0/164 (0%)]\t Loss: 2.275805\n",
      "Train Epoch: 90 [112/164 (64%)]\t Loss: 1.736776\n",
      "Train Epoch: 91 [0/164 (0%)]\t Loss: 1.860108\n",
      "Train Epoch: 91 [112/164 (64%)]\t Loss: 1.658359\n",
      "Train Epoch: 92 [0/164 (0%)]\t Loss: 1.838348\n",
      "Train Epoch: 92 [112/164 (64%)]\t Loss: 1.820460\n",
      "Train Epoch: 93 [0/164 (0%)]\t Loss: 1.813031\n",
      "Train Epoch: 93 [112/164 (64%)]\t Loss: 1.996608\n",
      "Train Epoch: 94 [0/164 (0%)]\t Loss: 2.139825\n",
      "Train Epoch: 94 [112/164 (64%)]\t Loss: 1.919871\n",
      "Train Epoch: 95 [0/164 (0%)]\t Loss: 1.809336\n",
      "Train Epoch: 95 [112/164 (64%)]\t Loss: 1.695043\n",
      "Train Epoch: 96 [0/164 (0%)]\t Loss: 1.931562\n",
      "Train Epoch: 96 [112/164 (64%)]\t Loss: 2.017806\n",
      "Train Epoch: 97 [0/164 (0%)]\t Loss: 1.682246\n",
      "Train Epoch: 97 [112/164 (64%)]\t Loss: 1.656627\n",
      "Train Epoch: 98 [0/164 (0%)]\t Loss: 1.721757\n",
      "Train Epoch: 98 [112/164 (64%)]\t Loss: 1.991427\n",
      "Train Epoch: 99 [0/164 (0%)]\t Loss: 1.683031\n",
      "Train Epoch: 99 [112/164 (64%)]\t Loss: 1.982182\n",
      "Train Epoch: 100 [0/164 (0%)]\t Loss: 1.917302\n",
      "Train Epoch: 100 [112/164 (64%)]\t Loss: 1.751277\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nchannels = 1\\naugment = 1\\nfilters = 64\\n\\nmodel = nn.Sequential(\\n    ConvODE(channels, filters, augment, 2125),\\n    nn.Flatten(),\\n    NeuralODE((channels+augment)*2125, 7, int(2125/2), order=5),\\n    nn.Softmax(dim=0)\\n).to(device)\\n\\noptimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\\n\\n\\nfor epoch in range(args.epochs+1):\\n    model.train()\\n    correct = 0\\n    for batch_idx, (X, y) in enumerate(trainloader):\\n        X, y = X.to(device), y.to(device)\\n        optimizer.zero_grad()\\n        y_hat = model(X)\\n        loss = nn.CrossEntropyLoss()(y_hat, y)\\n        loss.backward()\\n        optimizer.step()\\n        pred = y_hat.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\\n        correct += pred.eq(y.view_as(pred)).sum().item()\\n        if batch_idx % args.log_interval == 0:\\n            print(\\'Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\\'.format(\\n                epoch, batch_idx * len(X), len(trainloader.dataset),\\n                100. * batch_idx / len(trainloader), loss.item()))\\n    accuracy = 100. * correct / len(trainloader.dataset)\\n    print(\"Accuracy = {:.3f}%\".format(accuracy))\\n    scheduler.step()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    epochs = 100\n",
    "    lr = 1e-5\n",
    "    weight_decay = 1e-4\n",
    "    log_interval = 7\n",
    "args = Args()\n",
    "\n",
    "\n",
    "##############\n",
    "#code for vae#\n",
    "##############\n",
    "\n",
    "model = FlowODEVAE(in_dim=2125, in_channels=1, conv_channels=32, augment_dim=1, latent_dim=15, order=4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs+1):\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(trainloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        X_hat, mu, var, z, trace_J = model(X)\n",
    "        loss = Loss(X_hat, X, mu, var, trace_J)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(X), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "\n",
    "               \n",
    "\n",
    "#####################\n",
    "#code for classifier#\n",
    "#####################\n",
    "'''\n",
    "channels = 1\n",
    "augment = 1\n",
    "filters = 64\n",
    "\n",
    "model = nn.Sequential(\n",
    "    ConvODE(channels, filters, augment, 2125),\n",
    "    nn.Flatten(),\n",
    "    NeuralODE((channels+augment)*2125, 7, int(2125/2), order=5),\n",
    "    nn.Softmax(dim=0)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs+1):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (X, y) in enumerate(trainloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(X), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "    accuracy = 100. * correct / len(trainloader.dataset)\n",
    "    print(\"Accuracy = {:.3f}%\".format(accuracy))\n",
    "    scheduler.step()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPl_veJfewXu"
   },
   "source": [
    "Note: when I augement the data in the ConvODE() module using a neural network (rather than initializing the augmented dimension to zero), the training is much much slower. However the training is much better. See 'self.augment' in ConvODE() and swap out for commented version for quicker training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-O4ZwipuF6d",
    "outputId": "290939a8-a77b-4428-87e6-f323c6a3458d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20738070"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of trainable parameters\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
